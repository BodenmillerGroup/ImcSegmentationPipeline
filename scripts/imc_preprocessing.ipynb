{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df251db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# !{sys.executable} -m pip install -e {Path.cwd().parent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imcsegpipe\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import List\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e5475",
   "metadata": {},
   "source": [
    "\n",
    "# The IMC preprocessing pipeline for multiplexed image analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e09020",
   "metadata": {},
   "source": [
    "This is a pipeline to segment IMC data using Ilastik pixel classification as well as\n",
    "CellProfiler.\n",
    "\n",
    "To run install the conda `imctools` envrionment found in `Setup/conda_imctools.yml`.\n",
    "\n",
    "  - Install conda\n",
    "\n",
    "  - On a conda console type: `conda env create -f setup/conda_imctools.yml`\n",
    "\n",
    "Start a Jupyter instance in this environment to run this Jupyter Notebook.\n",
    "\n",
    "This notebook will automatically download example data.\n",
    "\n",
    "This dataset are zipped input_data_folders_path_inputs of the `.mcd` and all `.txt`\n",
    "files corresponding to one acquisitions session.\n",
    "This is my recomended data format as it preserves and contains all original metadata\n",
    "and enforces a consistent naming scheme.\n",
    "\n",
    "Note that the `description` image name can be found in the `..._Acquisition_meta.csv`\n",
    "generated together with the ome tiffs\n",
    "as well as in the `cpinp` folder later in the script.\n",
    "After analysis the `Image.csv` metadata file generated in Cellprofiller will also\n",
    "contain the `Description` as well as other important metadata for each\n",
    "image, such as acquisition frequency, time, location etc.\n",
    "\n",
    "For working with `.txt` files, please look at the older examples.\n",
    "\n",
    "For any feedback please contact: Vito, vito.zanotelli@uzh.ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59626637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input_data_folders_path_inputs with the ziped acquisition files for the analysis\n",
    "raw_dirs = [\"../raw\"]\n",
    "\n",
    "# output for OME tiffs\n",
    "work_dir = \"../analysis\"\n",
    "\n",
    "# panel\n",
    "panel_file = \"../config/example_panel.csv\"\n",
    "panel_channel_col = \"Metal Tag\"\n",
    "panel_keep_col = \"full\"\n",
    "panel_ilastik_col = \"ilastik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ad642",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dirs = [Path(raw_dir) for raw_dir in raw_dirs]\n",
    "work_dir = Path(work_dir)\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# parameters for resizing the images for ilastik\n",
    "acquisitions_dir = work_dir / \"ometiff\"\n",
    "analysis_dir = work_dir / \"tiffs\"\n",
    "ilastik_dir = work_dir / \"ilastik\"\n",
    "cellprofiler_input_dir = work_dir / \"cpinp\"\n",
    "cellprofiler_output_dir = work_dir / \"cpout\"\n",
    "histocat_dir = work_dir / \"histocat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will download the example data - remove if you work with your own data!\n",
    "example_dir = raw_dirs[0]\n",
    "example_dir.mkdir(exist_ok=True, parents=True)\n",
    "for example_file_name, example_file_url in [\n",
    "    (\n",
    "        \"20170905_Fluidigmworkshopfinal_SEAJa.zip\",\n",
    "        \"https://www.dropbox.com/s/awyq9p7n7dexgyt/\"\n",
    "        \"20170905_Fluidigmworkshopfinal_SEAJa.zip?dl=1\",\n",
    "    ),\n",
    "    (\n",
    "        \"20170906_FluidigmONfinal_SE.zip\",\n",
    "        \"https://www.dropbox.com/s/0pdt1ke4b07v7zd/\"\n",
    "        \"20170906_FluidigmONfinal_SE.zip?dl=1\",\n",
    "    ),\n",
    "]:\n",
    "    example_file = example_dir / example_file_name\n",
    "    if not example_file.exists():\n",
    "        request.urlretrieve(example_file_url, example_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80dc4b",
   "metadata": {},
   "source": [
    "Convert mcd containing input_data_folders_path_inputs into imc zip\n",
    "input_data_folders_path_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dirs: List[TemporaryDirectory] = []\n",
    "try:\n",
    "    for raw_dir in raw_dirs:\n",
    "        zip_files = list(raw_dir.rglob(\"*.zip\"))\n",
    "        if len(zip_files) > 0:\n",
    "            temp_dir = TemporaryDirectory()\n",
    "            temp_dirs.append(temp_dir)\n",
    "            for zip_file in sorted(zip_files):\n",
    "                imcsegpipe.extract_zip_file(zip_file, temp_dir.name)\n",
    "    acquisition_metadatas = []\n",
    "    acquisitions_dir.mkdir(exist_ok=True)\n",
    "    cellprofiler_input_dir.mkdir(exist_ok=True)\n",
    "    for raw_dir in raw_dirs + [Path(temp_dir.name) for temp_dir in temp_dirs]:\n",
    "        mcd_files = list(raw_dir.rglob(\"*.mcd\"))\n",
    "        if len(mcd_files) > 0:\n",
    "            txt_files = list(raw_dir.rglob(\"*.txt\"))\n",
    "            matched_txt_files = imcsegpipe.match_txt_files(mcd_files, txt_files)\n",
    "            for mcd_file in mcd_files:\n",
    "                acquisition_metadata = imcsegpipe.extract_mcd_file(\n",
    "                    mcd_file,\n",
    "                    acquisitions_dir / mcd_file.stem,\n",
    "                    txt_files=matched_txt_files[mcd_file],\n",
    "                )\n",
    "                acquisition_metadatas.append(acquisition_metadata)\n",
    "    acquisition_metadata = pd.concat(acquisition_metadatas, copy=False)\n",
    "    acquisition_metadata.to_csv(cellprofiler_input_dir / \"acquisition_metadata.csv\")\n",
    "finally:\n",
    "    for temp_dir in temp_dirs:\n",
    "        temp_dir.cleanup()\n",
    "    del temp_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17734dd-4681-482f-ae1e-cdb3c8eb18bf",
   "metadata": {},
   "source": [
    "Export a copy of the panel to the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellprofiler_output_dir.mkdir(exist_ok=True)\n",
    "shutil.copy2(panel_file, cellprofiler_output_dir / \"panel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a304e00",
   "metadata": {},
   "source": [
    "Convert ome.tiffs to a HistoCAT compatible format, e.g. to do some visualization and\n",
    "channel checking.\n",
    "\n",
    "Only required if HistoCAT is used as an image browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "for acquisition_dir in acquisitions_dir.glob(\"*\"):\n",
    "    if acquisition_dir.is_dir():\n",
    "        imcsegpipe.export_to_histocat(acquisition_dir, histocat_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3c843",
   "metadata": {},
   "source": [
    "Generate the analysis stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320202b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel: pd.DataFrame = pd.read_csv(panel_file)\n",
    "for acquisition_dir in acquisitions_dir.glob(\"*\"):\n",
    "    if acquisition_dir.is_dir():\n",
    "        imcsegpipe.create_analysis_stacks(\n",
    "            acquisition_dir,\n",
    "            analysis_dir,\n",
    "            panel.loc[panel[panel_keep_col] == 1, panel_channel_col].tolist(),\n",
    "            suffix=\"_full\",\n",
    "            hpf=50.0,\n",
    "        )\n",
    "        imcsegpipe.create_analysis_stacks(\n",
    "            acquisition_dir,\n",
    "            analysis_dir,\n",
    "            panel.loc[panel[panel_ilastik_col] == 1, panel_channel_col].tolist(),\n",
    "            suffix=\"_ilastik\",\n",
    "            hpf=50.0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab99527",
   "metadata": {},
   "source": [
    "Copy one csv containing the channel order of the full stack in to the cellprofiler\n",
    "input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece67368",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellprofiler_input_dir.mkdir(exist_ok=True)\n",
    "first_channel_order_file = next(analysis_dir.glob(\"*_full.csv\"))\n",
    "shutil.copy2(first_channel_order_file, cellprofiler_input_dir / \"full_channelmeta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65ffd8",
   "metadata": {},
   "source": [
    "Generate channel metadata for the probability stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a25f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellprofiler_input_dir.mkdir(exist_ok=True)\n",
    "probab_meta = [\"CellCenter\", \"CellBorder\", \"Background\"]\n",
    "with open(cellprofiler_input_dir / \"probab_channelmeta_manual.csv\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(probab_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351fdc44",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "This concludes the conversion of the IMC rawdata into usable TIFFs.\n",
    "\n",
    "The pipelines can be found in the `cp4_pipeline` folder in this repository. They were\n",
    "tested in `cellprofiler 4.0.6).\n",
    "\n",
    "The next steps are:\n",
    "\n",
    "### A) Cellprofiler: 1_prepare_ilastik\n",
    "\n",
    "In this module we prepare the data for Ilastik pixel classification, by first removing\n",
    "strong outlier pixels, then scaling the images 2x and then taking random 500x500 crops\n",
    "to do the train the pixel classifier.\n",
    "\n",
    "Note: for large datasets 250x250 crops or smaler should suffice!\n",
    "\n",
    "The following parts of this module need to be adapted:\n",
    "\n",
    "1) File list: choose all files in the `tiff` subfolder\n",
    "\n",
    "2) Default Output Folder: Choose the `ilastik` subfolder\n",
    "\n",
    "No further parts need to be adapted.\n",
    "In our 16 core computer this step takes ca 5 min for the example dataset.\n",
    "\n",
    "\n",
    "### B) Ilatik: Train a pixel classifier\n",
    "\n",
    "This uses the random crops generated in the last step.\n",
    "\n",
    "1) Make a new `pixel classification project`. An example project that works with the\n",
    "example data can be found in the 'analysis' subfolder.\n",
    "\n",
    "2) Add the `.h5` random crops: Raw data -> Add Seperate Images -> Select all `.h5`\n",
    "images in the `ilastik` subfolder.\n",
    "\n",
    "3) Proceed to `Feature Selection`\n",
    "\n",
    "4) Select suitable features (or just everything >= 1 pixels)\n",
    "\n",
    "5) Proceed to the classification:\n",
    "\n",
    "    - Add 3 labels (for large datasets adding the labels can take a while):\n",
    "        - 1: Nuclei\n",
    "        - 2: Cytoplasma/membrane\n",
    "        - 3: Background\n",
    "    - Start labeling:\n",
    "        - The box next to `Input Data` can change the channels. What each channel\n",
    "          corresponds to can be seen when looking in any of the `..._ilastik.csv`\n",
    "          files in the `tiff` folder. The 0 channel correspond to the sum of all\n",
    "          channels, very usefull to label the background.\n",
    "        - Use window leveling change the contrast. Right click on the `Input Data` ->\n",
    "          `Adjust Thresholds` is also very usefull\n",
    "        - Label opiniated: If you see in the nucleus channel that two nuclei are stuck\n",
    "          together but have a faint dip in intensity in between, label this as 2:\n",
    "          Cytoplasma. Encyrcle nuclei with Cytoplasma\n",
    "        - Diseable `Live Update` for performance\n",
    "        - Frequently check the `Uncertainties`: This indicates which pixels the\n",
    "          classifier profits most if they are labeled. A well trained classifier has\n",
    "          low uncertainty within class regions (e.g. Nuclei) and high uncertainty at\n",
    "          class borders (e.g. between nuclei and cytoplasma).\n",
    "\n",
    "    - If you think the classifier is well trained, export the probabilities:\n",
    "        - Export Settings -> Source: Probabilities -> Choose Export Image Settings:\n",
    "            - Convert to datatype: Unsigned Integer 16 bit\n",
    "            - Renormalize: check\n",
    "            - Format: Tiff\n",
    "            - File: leave default\n",
    "        - Export all: This generates `_Probabilities.tiff` in the `ilastik` folder.\n",
    "          They can be checked using any image viewer\n",
    "            - To generate uncertainty maps (good to identify regions that need\n",
    "              training), run the `Convert probabilities to uncertainties` section\n",
    "              `#For training` below. This will put uncertainties in the uncertainty\n",
    "              folder.\n",
    "            - Well trained classifiers have low uncertainty (transparent) everywhere\n",
    "              but at class borders which should be white.\n",
    "\n",
    "        - Optional: Train again regions with high uncertainty, then proceed.\n",
    "\n",
    "        - Batch processing: -> Select raw data files -> select all `_s2.h5` files in\n",
    "          the `tiff` folder. (sort by filetype, select all `H5` files).\n",
    "            - This step takes a while and is computationally intensive!\n",
    "            - Ca 15 min on 10 cores on the example data\n",
    "\n",
    "        - Optional: use the below probability to uncertainty `#For the data` to\n",
    "          convert all proabilities to uncertainties, check if there are any regions of\n",
    "          high uncertainty and optionally crop the corresponding image part in imagej\n",
    "          and add it to the training data.\n",
    "        - Note: store the `ilastik` folder with all the random crops and the trained\n",
    "          classifier for reproducibility reasons.\n",
    "\n",
    "### C) Cellprofiler: 2_segment_ilastik\n",
    "\n",
    "This step will segment the probabilities into masks.\n",
    "\n",
    "Things to adapt:\n",
    "\n",
    "1) File list: choose again all files from the `tiffs` folder\n",
    "\n",
    "2) It is important to check the `IdentifyPrimaryObjects` step, if the segmentation\n",
    "   settings are suitable! This might vary strongly between cell/tissue/training and\n",
    "   needs attention! Use the test mode and try various settings. Also note the `smooth`\n",
    "   step immediately before: This can be also removed, I just happen get good results\n",
    "   with this additional step.\n",
    "\n",
    "3) Also the `MeasureObjectSizeShape` combined with `FilterObjects` is just some\n",
    "   personal preference of mine, feel free to change\n",
    "\n",
    "4) `IdentifySecondaryObjects`: Here th mask is expanded to the full cell.\n",
    "\n",
    "5) `Rescale objects`: note that our segmentation was done on 2x upscaled images, this\n",
    "   scales the masks down again. Note that potentially also the nuclei mask could be\n",
    "   scaled down and further exported and used.\n",
    "\n",
    "6) The `Default Output Path` does not need to be adapted for this module.\n",
    "\n",
    "\n",
    "Note: Seperating mask generation from mask measurement adds modularity and is thus\n",
    "highly recommended, as generating masks is one of the most resource intensive steps.\n",
    "\n",
    "\n",
    "### D) Cellprofiler: 3_measure_mask\n",
    "\n",
    "This step is not necessary for `HistoCat` only analysis. If `HistoCat` should be used,\n",
    "use the `Generate the histocat folder with masks` section below.\n",
    "\n",
    "#### 3_measure_mask_basic\n",
    "\n",
    "This module measures without considering spillover correction.\n",
    "\n",
    "1) File list: choose again all files from the `tiffs` folder\n",
    "\n",
    "2) View Output settings: set the `Default output folder` to the `cpout` folder and the\n",
    "   `Default input folder` to the `cpint` folder.\n",
    "\n",
    "3) Metadata: update - this will automatically merge the mcd metadata .csv generated\n",
    "   earlier in the script with your images.\n",
    "\n",
    "4) Names and types: click update\n",
    "\n",
    "5) `Measure Object Intensity Multichannel`: Adapt the channel numbers. Check the\n",
    "   `_full.csv` files in the `tiffs` folder to see how many channels the stack have\n",
    "   and adapt accordingly.\n",
    "\n",
    "6) `Measure Image Intensity Multichannel`: Adapt the channel numbers. Check the\n",
    "   `_full.csv` files in the `tiffs` folder to see how many channels the stack have\n",
    "   and adapt accordingly.\n",
    "\n",
    "Notes:\n",
    "- In this pipeline all the intesities are scaled by `1/(2**16)`\n",
    "- The mapping between channel number c1, c2, c3 corresponds to the position in the\n",
    "  `_full.csv`s found in the `tiffs` folder.\n",
    "    - The original acquisition description, acquisition frequencies etc can be found\n",
    "      in the `Image.csv` output as `Metdata_...` columns.\n",
    "    - This outputs a lot of measurements that are acutally of little interest -\n",
    "      usually we only look at `meanintensity` per channel and cell. To reduce the\n",
    "      outputs, select in `Export To Spreadsheet` -> `Select Measurementsto Export` ->\n",
    "      Only the measurements you want (usually all Image measurements and only the\n",
    "      `MeanIntensity` fullstack measurements).\n",
    "- The `FullStack` can also be not measured, as it is almost identical to the\n",
    "  `FullStackFiltered`.\n",
    "\n",
    "#### 3_measure_mask_compensated\n",
    "This will also have a spillover corrections step - stay tuned!\n",
    "\n",
    "\n",
    "### E) Pipeline output\n",
    "\n",
    "The pipeline output is all in the `cpout` folder.\n",
    "\n",
    "Files and folders:\n",
    "\n",
    "- Image.csv: Image level metadata\n",
    "\n",
    "- var_Image.csv: Metadata for the colums in Image.csv.\n",
    "  This contains also metadata from the IMC such as acquisition coordinates.\n",
    "\n",
    "- {object}.csv: eg cell.csv, contains cell slice level measurements\n",
    "\n",
    "- var_{object}.csv: eg var_cell.csv: contains metadata for the object measurements\n",
    "\n",
    "- panel.csv: a copy of the panel used for the input\n",
    "\n",
    "- Object relationships.csv: Object neighbourhood and other relationships\n",
    "\n",
    "- Experiment.csv: Metadata about the actual measurement run (eg pipeline used,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e364ec",
   "metadata": {},
   "source": [
    "## Generate the histocat folder with masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83673a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for acquisition_dir in acquisitions_dir.glob(\"*\"):\n",
    "    if acquisition_dir.is_dir():\n",
    "        imcsegpipe.export_to_histocat(\n",
    "            acquisition_dir, histocat_dir, mask_dir=analysis_dir\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "auto:percent,ipynb",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
