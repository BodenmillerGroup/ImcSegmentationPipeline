\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% draft
\usepackage{draftwatermark}
\SetWatermarkText{DRAFT}
\SetWatermarkScale{1}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\setlength{\parskip}{\baselineskip}%
\title{A flexible image segmentation pipeline for heterogenous multiplexed tissue images based on pixel classification}
\author{Vito Zanotelli \& Bernd Bodenmiller}

\begin{document}
\maketitle

\begin{abstract}
Measuring objects and their intensities in images is basic step in many quantitative tissue image
analysis workflows. We present a flexible and scalable image processing pipeline tailored to
highly multiplexed images. This pipline allows the single cell and image structure segmentation of
hundereds of imagese. It is based on supervised pixel classifcation using Ilastik to the destill the
segmentation relevanat information from the multiplexed images in a semi automated fashion,
followed by standard image segmentation using CellProfiler. We provide a helper python package as
well as customized CellProfiler modules that allow for a straight forward application of this
workflow. As the pipeline is entirely build on open source tool it can be easily adapted to more
specific problems and forms a solid basis for quantitative multiplexed tissue image analysis.

\end{abstract}


\section{Introduction}
Image segmentation, i.e. division of images into meaningful regions, is
commonly  used for quanitative image analysis
\cite{carpenter_cellprofiler:_2006,mccabe_automated_2005}.  Tissue level comparisons often
involve segmention of the images in macrostructures, such as tumor and stroma, and calculating
intensity levels and distributions in such structures \cite{mccabe_automated_2005}.  Cytometry type tissue analysis aim to
segment the images into pixels belonging to the same cell, with the goal to ultimatively identify
cellular phenotypes and celltypes \cite{carpenter_cellprofiler:_2006}.  Classically these approaches are mostly based on a single, hand
selected nuclear marker that is thresholded to identify cell centers. If available a single membrane
marker is used to expand the cell centers to full cells masks, often using watershed type algorithms.  However
nowadays several approaches have become avaiable that allow a highly multiplexed measurement of
molecular markers, allowing images with as many as 40 markers. In such images several markers have
potentially information about the nuclear, cytoplasmic or membrane information of a pixel.  Correspondingly it
was already shown that a segmentation based on an optimized selection of a linear combination of
these markers outperforms any single hand selected nuclear and membrane channel for segmentation
\cite{schuffler_single_2014}. However this approach does not utilize the interdependencies as well as texture
information of markers present in such images. Supervised classificaiton of pixels into relevant classes, such as
nuclear-like and background-like, has been already proposed to be used to integrade the information
encoded in the texture of high resolution but low diminsional images into probability maps that facilitate segmentation
\cite{joyseeree_using_2013,sommer_learning-based_2012-1,logan_quantifying_2016, sommer_ilastik:_2011}.
We argue that this approach should also be particularly suited to
integrate the channel information and textures found in multiplexed images. A flexible classification algorithm such as implemented in the Ilastik open source software should allows for a
flexible pixel classification, that can be used to identify nuclear as well as membrane or
cytoplasmic pixels over a wide range of cell types and phenotypes, after expert guided supervised
training. Segmenting the resulting probabilty maps, indicative of the class association of the
trained pixels, should allow for a robust cell identification by using segmentation routines
implemented in softwares such as CellProfiler (Fig. \ref{fig:class}).

\begin{figure}[htb]
\centering
\includegraphics[width=0.95\textwidth]{pixel_classification_workflow.pdf}
\caption{Ilastik is used to classify pixels according to nuclear
(red), membrane/cytoplasma (yellow) and background (green) (d)
using information from various channels (a-c). This achieves an
integration of the class information from all available channels in a
semi-supervised manner. Cellprofiler is used to segment the class probability maps (white)
to get nuclear (e) and cell level (f) segmentation masks.
	(g) shows an example probability
	map with (h) the corresponding segmentation. These masks are used to extract single cell information, such as mean
marker levels and neighbourhood graphs using CellProfiler.
\label{fig:class}
} 
\end{figure}


We used this idea to build a flexible and scalable image processing pipeline to segment highly
multiplexed images (Fig. \ref{fig:pipeline}). We defelopped the approach  based on the multiplexed imaging technique imaging mass
cytometry \cite{giesen_highly_2014}. IMC allows the measurement off more
than 40 markers at a resolution of 1um in tissue sections, by exploiting a metal labeled antibody
stain with a laser ablation coupled induced coupled plasma mass spectrometer. IMC rawdata contains
the pixel data in a flow-cytometry like pixel data filestructure. Thus we build a python based
converter package to convert the raw data formats into a standardized ome.tiff format
\cite{goldberg_open_2005}. This standardized format is the basis for the further pipeline. IMCtools
can convert ome.tiff into formats and image stacks that can be directly used in CellProfiler and for Ilastik pixel classification.
To build an optimized pipeline, existing CellProfiler modules were adapted and new modules written to facilitate the handling of the
highly multiplexed image data and to allow for measurement of channel intensities as well as texture features of
whole multiplexed image stacks. The resulting single cell masks and data can then be directly used in data
anlysis scripts as well as visualization tools such as HistoCAT \cite{schapiro_histocat:_2017}. 

\newpage
\section{Material and Methods}
In the following section we give a detailed user guide for the proposed pipeline. Example
configuration files and the mentionned CellProfiler pipelines can be found on the following github page: \url{https://github.com/BodenmillerGroup/ImcSegmentationPipeline}
\subsection{Pipeline overview}
The developed image pipline consists of the general steps:
\begin{itemize}
\item Installation of the required software
\item Conversion of IMC data into a common file format
\item Preparation of the pipeline metadata
\item Generation of the analysis stacks 
\item Preparation of the input stacks for Ilastik
\item Iterative training of the Ilastik pixel classifier
\item Single cell segmentation using CellProfiler
\item Multiplexed image measuremetns using CellProfiler
\item EFurther analysis of the single cell data
\end{itemize}

\begin{figure}[htb]
\centering
\includegraphics[width=0.75\textwidth]{Figure2.pdf}
\caption{
A schema of the proposed workflow. A) The imctools python package is
used to convert rawdata into ome.tiff and prepares analysis stacks. Various tools can be used for
image visualization. B) The ilastik analysis stack is preprocessed using CellProfiler C) Iterative Ilastik pixel classification is
used to generate probability maps. D) The probability maps are segmented to single cell masks using
CellProfiler. E) Cellprofiler is used to generate single cell data in a standardized format. F) The
single cell data can be analyzed using various tools.
\label{fig:pipeline}
}
\end{figure}

\subsection{Installation of the required software}
This pipeline was build for the use on Ubuntu using Python2, but it's crossplatform compatible nature should
allow the deployment also on Windows as well as MacOS as well as Python3.

First CellProfiler (tested version 2.2.0)  needs to be installed. For full compatiblity CellProfiler should be direclty
installed as a python package, as documented by CellProfiler. Then Ilastik should be installed,
according to the standard Ilastik installation procedure (tested version 1.2.2).

This pipeline uses Jupyter notebooks as ad-hoc configuration files and to build data conversion
pipelines. Thus jupyter as well as ipython need to be installed.
(\url{http://jupyter.org/install.html}).
 
The imctools IMC file conversion package can be installed directly from github
(\url{https://github.com/BodenmillerGroup/imctools}) using the python \textit{pip} package manager.

For the multiplexed image CellProfiler plugins the  ImcPluginCP Github repository folder needs to
be copied to the machine (\url{https://github.com/BodenmillerGroup/ImcPluginsCP}. The CellProfiler plugin folder needs to be set correspondingly in the
CellProfiler settings. For full functionality of all modules, the \textit{tifffile} python package needs
to be installed for the Python version that CellProfiler is using. 

If compensation should be applied to the images, a spillover matrix needs to be first generated as describe in
the paper \cite{stephane_chevrier_channel_2017}. Further R, the R package \textit{CATALYST} and the
python package \textit{Rpy2}
(version 2.8.2) need
to be installed accoring to the standard installation instructions.

\subsection{Conversion of IMC data into a common file format}
IMC data commonly comes as a vendor controlled .mcd or .txt file. To make the following pipeline
generally applicable to multiplexed imaging data and independent of the vendor format, the raw
files are first converted into an ome.tiff format \cite{goldberg_open_2005}.

For IMC data this one multiplane tiff file per acquisition. Each channel needs to have the channel
label attribute as well as the fluor attribute set. For IMC data the metal name followed by the
isotopic mass are used with the form: (IsotopeShortname)(Mass), e.g. Ir191 for Iridium isotope 191.

With the IMCtools, the conversion can be either done in the Juptyter notebook script (see cell xx in the example
notebook) or via the command line tool (\texttt{python -m
imctools.scripts.imc2tiff -h}) .

The imctool  python module can additionally be installed in Imagej/FIJI \cite{schneider_nih_2012} as a Jython plugin, by
dragging it into the FIJI plugin folder. Afterward the \textit{load imc file} Jython script can be used in
the imctools section of the Plugins folder to load and convert IMC raw data files such as .txt and
.mcd files. Note that this uses pure Jython in can be rather slow. During loading the images are
automatically converted to .ome.tiffs. We further provide the convenience function 'load
multichannel ome' that will load the IMC image as an Image5D image. If prefered the Image5D image
can be easily converted to a normal stack using the Image5D 'Image5D to stack' function. This
allows the visualization of the raw imc data using ImageJ.

For aditional visualization, the imctool \textit{omefolder2micatfolder} script can be used to convert the
ome.tiff images into a HistoCat compatible format (\texttt{python -m imctools.scripts.omefolder2micatfolder -h}).

\subsection{Preparation of the pipeline metadata}
The pipeline needs several configuration settings:
\begin{enumerate}
\item folders: A  list of folders containing OME TIFFs to be analyzed.
\item common file part: A string that should be contained in all the images to be analyzed. (empty
if all, often .txt to convert only .txt images)
\item pannel csv: a comma seperated table containing at least the following columns:

\begin{itemize}
\item Metal column: A column containing the metal/channel names in the same format as present in
	the OME tiff as \textit{Fluor} attribute
\item Ilastik column: A column containing 1 for channels that contain valuable information for
segmentation, 0 otherwise. Note that these are the channels used for the later pixel classification
step. Channels should optimally contain clear nuclear, cytoplamic or membrane localized signal. The
more channels included the more computationally intensive the Ilastik pixel classification will be.
\item Full columns: A column containing 1 for all channels that should be measured with
CellProfiler.
\end{itemize}

\item Analysis folder: The folder where the images stack for the CellProfiler analysis will be
stored.
\item HistoCAT folder: The folder where the HistoCAT folder structure should be generated

\item Spillover CSV: A spillover matrix in the CSV format. E.g. exported from the R CATALYST
package.


\item Additionally there are several column/file naming convention variables:

\begin{itemize}
\item sm\_outname: the name of the adapted spillover matrix (default: sm\_full)
\item suffix\_full: the suffix appended to the filename for full stacks (default: \_full
\item suffix\_ilastik: the suffix appended to the filename for the ilastik stacks (default:
\_ilastik)
\end{itemize}
\end{enumerate}

\subsection{Generation of the analysis stacks}
After adapting the metadata in the Jupyter notebook, the ome.tiffs are converted into CellProfiler
and Ilastik compatible tiff files. This will extract
the channels indicated in the channel csv from the .ome.tiff into stacks ready for analysis with
CellProfiler and Ilastik. Per default this will include 'Full' stack, containing all 
the channels chosen for CellProfiler quantification as well as the 'Ilastik' stack, containing all the
channels selected for the Ilastik pixel classification. Additionally the Ilastik stack will contain
the sum of all selected channels as the first channel, as this is often useful to discriminate
background from tissue material. It is straight forward to modify this step to generate additional
stacks, e.g. for additional tissue structure segmentations.

\subsection{Preparation of input stacks for Ilastik}
This step will allow a preprocessing of the images used for pixel classification using CellProfiler (example
pipeline 1\_ilastik\_preprocessing). Common steps include removing outlier pixels (custom module Smooth Multichannel, 'Remove single hot pixels') as well as scaling the
images two fold. In our experience scaling the images two fold facilitates the manual pixel
classification using Ilastik considerable when using low resolution images such as produced by IMC.
Additionally we recommend to crop random section from the image and only use these for training.
Often the tissue structures on an image are rather similar, thus cropping of the random section will allows to train the pixel
on smaller images, reducing the computiational requirements of the classification.
The preprocessed images are saved in a seperate pixel classification folder using the adapted
module xxx, which saves the images in the xyc format, such that color planes are
recognized correctly in Ilastik.


\subsection{Pixel classification using Ilastik}
To train the Ilastik pixel classifier, an instance of Ilastik is opened and a new
pixel-classification workflow is generated \cite{sommer_ilastik:_2011}. Then the image crops exported for ilastik
classification should be loaded as training data.
As a next step in ilastik, the features fore classification are selected. We recommend genererally to select features generously
herei (all features between 1 and 10 pixels), if the computational resourcess allow it, and use the
Ilastik 'suggest feature' feature selection after some initial training.
In the next step the pixel classification is performed. For this step 3 classes: nuclear,
cytoplamic/membrane and background pixels are created.
The classifier can be trained by generating a training set by manually drawing pixels for the
respective classes. A training is most effective, if it contains a diverse collection of pixels and not to many
very similar pixels. Thus we recommend to use a small brush size (e.g. 1 pixel) and label sparsely,
as nearby pixels are often nearly identical.
The channels can be changed in the lower left corner of the
classification window in the input-channel layer. As the channels can have widely different intensities, the 'window leveling'
tool should be used to adjust the visualization.
To maximize the training efficiency we recommend to first draw some obvious pixels, e.g. from
known nuclear and membrane channels. Then the 'live update' should be activated and the
'Uncertainty' checked. Pixels with high uncertainty provide the highest value for new training data
and thus they should be preferrably manually classified. Classification should be done until the
uncerctainty looks low (=transparent) except for the class borders, e.g. arround nuclei.
Once the uncertainties for an image crop look good, other image crops should be checked.
To systematically check the uncertainty for all images we also recommend to use the 'Prediction
Export' function to export the uncertainties as easily browsable .PNG images.

Once the segmentation on the image crops look sufficiently certain, the 'Batch
processing' function of Ilastik can be used to convert the uncropped, scaled ilastik stacks into
probabilities. As an additional step we recommend to use the imctools script
'probabilities2uncertainties' to convert these probability maps into big uncertainty maps for
visual inspection. If there are regions not contained in the crops whose classification should be
improved, e.g. FIJI can be used to manually crop these regions and add them to the Ilastik input
data. 

\subsection{Single Cell Segmentation of probability maps using CellProfiler}
To segment the probabilty maps a Cellprofiler pipeline is used (pipline 2\_segment\_ilastik). First the probability map stack is
split into nuclear, cytoplasma/membrane and background. Then using the image-math module an image
with the sum of nuclear+cytoplasmic signal is generated.
The the 'IdentifyPrimaryObjects' module is used to segment the nuclear masks to identify nuclei.
Afterwards the 'IdentifySecondaryObjects' module is run with the nuclei and the
nuclear+cytoplasma image to identify cells.
As the segmentation is done on 2x scaled probability images, as a next step the modue 'rescale
objects' is used to rescale the masks to 1x resolution. This module removes pixels which are
ambiguous after rescaling as they are combinations of pixels from different objects at 2x
resolution. If wanted 'Identify secondary objects' can be used again on the cells to fill the gaps
generated by this approach.
Finally the masks are saved to be used in the next step.
Alternatively the masks and images can also be directly exported for HistoCAT analysis.

\subsection{Quantification of single cell features using cellprofiler}
The quantification of channels per object is done by using the Cellprofiler pipeline '3\_measure\_mask'. In this
pipeline the mask from the previous step as well as the full analysis stack, containing all the
channels to be analysed, are loaded. Additional image stacks, such as the probability stack, can be
loaded as well. Further filtering outlier pixels can be considered as a preprocessing step for the
anlaysis stack. If an experiment to assess the spillover matrix of the antibody conjugates was performed, at this step also the compensation can be applied to the images using the 'CorrectSpilloverApply' module.
Then the custom modules 'MeasureObjectIntensity Multichannel' as well as 'MeasureImageIntensity Multichannel' can be used to get object as
image level statistics. The standard module 'MeasureObjectNeighbors' can be used to identify the neightbourhood graph
of the objects.
Finally all these measurements can be saved.

\subsection{Further analysis of the single cell data}
The downstream analysis of the generated single cell data can be highly diverse. E.g. the exported
data can be loaded in R or python scripts for statistical analysis or can be visualized in tools
such as HistoCAT \cite{schapiro_histocat:_2017}. 
In cases were a spillover matrix was measured we suggest spillover Compensation using the CATALYST package.


\section{Results}
\subsection{Overview}
% make a figure to visualize the general concept
Segementing heterogenous tissue images is challenging, as often nuclear, cytoplasma and membrane markers are very
differentially expressed in different tissue parts. Using highly multiplexed images such as Imaging
Mass Cytometry images combined with a broad selection of clearly localized markers can useful for
this task, given that the multivariate nature of the data can be accounted for during the
semgentation step. We propose that segmentation of probability masks based on supervised pixel
classification is well suited for this task (Fig. \ref{fig:class}). Using the excellent Ilastik framework, the user
can browse the available channels to classify a training set of pixels into different classes, such
as nuclear, cytoplasmic/membranous and background pixels in the case of single cell segmentation.
This training data is then used to train a supervised, random forest based learning
algorithm is learning the pixel classes on the basis of all the channels as well as derived variants capturing
gradient as well as texture information \cite{sommer_ilastik:_2011}. After an iterative training process of the
 classifiers, probability maps for the trained classes can be
exported. These probability maps provide a highly integrated view of the image information contained in the
interdependencis, texture and gradients of the multiplexed image channels in respect to the classes
of interest. For single cell segmentation the nuclear probabilty as well as the cytoplasma/membrane
probabilities can be directly used by classical image segmentation algorithms, that usually expect
a nuclear as well as a cytoplamic/membranous channel for segmentation. These pixel probabilities
are strongly normalized, having values between 0 and 1, and are largely independent of actual
channel intensities. Further the random forest based training is flexible enough to learn complex marker
relationships in a robust way, even despite the large expression heterogeneity of markers present
in tissues.
Due to this standardized nature of the pixel probability maps, the segmentation can be run in a largely unsupervised maner,
making the approach suitable for a high throughput setting.


\subsection{Pipeline}
We implemented the above idea into an efficient, high throughput compabilte pipeline suited to
analyse heterogenous, multiplexed tissue image data (Fig. \ref{fig:pipeline}).
The approximate processing times per image are indicated for a 500x500 pixel image with 30
channels on a single computing core. A detailed step by step description can be found in the
Material and Methods.
As a first step of the pipeline the input
images are converted from vendor specific formats into a standardized ome.tiff image \cite{goldberg_open_2005}, making the pipeline suitable for a wide range of multiplexed imaging data (\texttildelow seconds). For
IMC data we developped the \textit{imctools} python packages to convert existing .txt and .mcd IMC images
formats into ome.tiffs. These ome.tiffs can either viewed in FIJI, using the imctools package as a
FIJI plugin or converted by \textit{imctools} for visualization in the HistoCAT or HistoCAT++
toolboxes.
Based on configuration files, the images are split into a stack containing all channels that should
be analyzed and a 'segmentation' stack containing the planes informative for segmentation
(\texttildelow seconds per image) using \textit{imctools}. As a rule of thumb we
recommend that all channels with clear localized markers should be used for segmentation.
The 'segmentation' stack is then preprocessed using CellProfiller and exported for Ilastik pixel
classification. For low-resolution IMC images, as part of the preprocessing the images are scaled
two fold. This allows an easier classification process as the images appear smoother. To make the
classification process more scalable, the random sections of fixed size are cropped for
classification during the preprocessing step (\texttildelow minutes).

For pixel classification the Ilastik software is used. The preprocessed and cropped segmentation
images are loaded and a selection of derived features, quantifying gradients and texture of
channels are calculated. For single cell segmentation of tissues, three classes are trained:
nuclear pixels, cytoplasmic/membrane pixels as well as background pixels. Based on the appearence
of individual marker channels, an expert user can interactively train the random forest based
classifier. We suggest to do an
itterative classification, trying to minimize the estimated uncertainty of the pixel classification
by visually inspecting the uncertainty maps.
Depending on the heterogeneity of tissue and the information content of the measured channels, this
classification can take several hours for large datasets containing hundereds of heterogenous
images.
The trained classfier can then be applied to the dataset in a batch mode (\texttildelow seconds-minutes).

Using CellProfiler the resulting probability maps are then segmented in two steps into a cell mask, by first
identifying the nuclear mask and then expanding it to the cellular mask (\texttildelow seconds-minutes)

The resulting mask can then be used to retrieve per-cell or object information from a stack of
channels using a Cellprofiler pipeline. To streamline the analysis with Cellprofiler, existing
CellProfiler modules were modified to allow an efficient measurement of large image stacks.
Additionally CellProfiler can be used to extract the neightbourhood graph of the cells. (\texttildelow minutes).

The single cell data can then be exported as standardized text files that can be analysed using
custom scripts or specialized software such as HistoCAT \cite{schapiro_histocat:_2017}.

The presented workflow takes an accumulated processing time in the order of 5-10 minutes per image.
Except for the manual pixel classification step, the processing of the pipeline can be fully
automatized and can be run in a parallelized fashion, scaling linearly with the number of images.
The manual pixel calssification step is the major bottleneck of the approach and the iterative
training can take hours. However this step uniquely allows the expert user to intuitively  train a classifier to
automatically integrate the complex and heterogeneous information contained in the multichannel images into
normalized images that are well suited for automatized analysis, e.g. using a watershed based
segmentation in CellProfiller.

Being fully based on open source sotware, this scalable pipeline provides an easy extendable basis
for a semi-automatized, high throughput analysis of multiplexed tissue images, taking full
advantage of the multivariate nature of the data for image segmentation. 

\section{Discussion}

The presented workflow allows for a high throghput semi-supervised image analysis of highly
multiplexed images.  The development version of this workflow has already been used for the HistCAT
publication, where it was used to segment 49 IMC images and was shown to yield biologially
reasonable segmentation
results \cite{schapiro_histocat:_2017}. Internally the
approach was already used for datasets with more than 800 images, showing the scalability of the
approach.

While supervised pixel classification provides an excellent framework to integrate complex image
pixel information into biological relevant classes, it has also several drawbacks. Needing manual
input, the classification  might have a significant expert bias. This was quantified as part of the
HistoCAT paper and the results showed no strong dependency of the analysis results based on
segmentations of different users \cite{schapiro_histocat:_2017}.

Particualry in low resolution imaging techniques such as IMC, which has an xy resolution of 1um and
a routinely used cut thickness of 5 um, a pixel might contain parts of nuclear as well as
cytoplasmic regions. These overlaps are often not obvious from a single channel, but can e.g. seen
by looking at nuclear as well as cytoplasmic channels simulatneoulsy. As a result the probability
map representation of the nuclear class is often smaller than one would judge by the nuclear signal
alone. While this has favorable properties for unclumping of nuclei during the segmentation, nuclear
segmentation will thus often lead to nuclear maskes that do not contain
the complete nuclear signal. We argue that this is mostly due to the physically overlapping of
pixel classes and thus is rather a problem of the low resolution used than this approach. We thus
suggest that the analysis should be mainly done on the expanded cell level.

Another issue specific to the low IMC image resolution is that it only allows subcellular
resolution by discriminating
between nuclear and cytoplasmic/membrane pixels, but no seperate distinction between cytoplasma and
membrane. Correspondingly the separation between neightbouring cells is notoriously difficult. We
partially address this problem by doing the pixel classification at a linear inerpolated two fold
upsampled resolution, which also makes the manual pixelclassification easier. When downsampling the
segmentation objects two the original resolution we initially remove pixels that would belong to two different cells at
two fold resolution, leaving an empty border between neightbouring cells. Due to the lack of
membrane specific membrane seperation between neightbouring cells we argue that these pixels would
be just randomly assigned to one or the other cells. Depending on the problem it might thus be
resonable to work with the mask with a gap or close it using another expansion step. Once the quality and resolution of IMC
images improved we highly recommend to correspondingly acknowledge the membrane structures
specifically to alleviate these problems.

A natural limitation of training a pixel classifier, is that the classifier can not be easily
transfered to new datasets, except if they have the same markers measured. However given that the
same markers used for classification are measured, we observe a transferability of a classifier
from one dataset to another. However we recommend to calculate the uncertainty maps of the predicted
images and screen for regions of high uncertainty, which should then be trained specifically. 
We speculate that in the future, provided a variable enough training
set and the use of a different classification implementation, a classifier trained on a single large dataset might be reused on new datasets with only minor
needs for retraining, making the pipeline even more automatized.


Being solely based on mature open source software, extending the pipeline is easy, mainly due to
the modular structure of CellProfiler and Ilastik, which forms the core of the pipeline.
Obvious extensions of the approach is to combine it with tissue level segmentation masks.
For example Ilastik can be used to classfiy the tissue into stroma and tumor areas, similarly
than used in the AQUA approach \cite{mccabe_automated_2005}. Measuring the resulting probability masks with the
cellular segmentation masks with CellProfiler allows to further integrate this level of
information.

Being build on CellProfiler, the output of this pipline is segmentation masks and single cell information in the standardized
CellProfiller output format. This forms a solid basis for more complex analysis e.g. with the
HistoCAT software for multiplexed image analysis or custom R and python scripts, or to import the
data in a standardized database.
% this part should have a better ending

\subsection{Comparison to existing workflows}
% Mibi: segmetnation of DNA signal in cellprofiler
% Giessen: Denis workflow
% Extensions: segment other structures, distance to structures etc
Classically single cell segmentation is done by using a nuclear marker to identify the cell center
and then applying watershed or similar algorithms to identify the outline of a cell using a
membrane marker \cite{carpenter_cellprofiler:_2006}. Correspondingly recent publications of multiplexed imaging
approaches perform a simple segmentation based on a nuclear and often another membrane channel, ignoring the
additional information encoded in the other acquired channels \cite{lin_highly_2015,
angelo_multiplexed_2014}.
A notable exception is the approach suggested by Schueffler et al \cite{schuffler_automatic_2015}. They identify
multiple membrane channels in multiplexed images based on the spearman correlation with a bait, user
defined membrane channel. Then they create a new 'meta' membrane channel, calculating a weighted
usm of the channels. The weighting of the channels is optimized by optimizing an 'segmentation
score', taking anto account the overlap of the masks with a user defined nuclear as well as membrane channel as well as the expected number of
cells. While taking informaion from more than one channel into account, this approach a) largely
depends on the validity of the semgentation score, b) a single, good bait membrane channel that is expresed
in most of the cells of interest, c) focuses heavily on the membrane channel identification. d)
does not incorporate singnal gradient and texture features.
Observing a better scalability and visual performance,  a real quantitative comparison of the approaches
is challenging and corresponing experiments are currently being performed. Conceptually we argue that the supervised machine
learning based approach is more flexible and makes better use of the segmentation relevant
information incorporated in the channels. Notably not only information about the membrane but also
about nuclear identity of the pixels is extracted from the masks. For example in cases were the
nuclear signal is very weak, the classifier will still identify a nucleus based on the absence of
non-nuclear markers.


\section{Conclusion}

We present a modular, scalable and flexible segmentation pipeline particularily suited for highly
multiplexed images largely based on the combination of the CellProfiler and Ilastik software.
Enabling an intuitive expert based classifciation with the flexible machine learning algorithm,
allows to destill pixel class information using all the available channel data and results in
easily segmentable probability maps. Altogether the presented workflow allows a high throughput
processing of hundereds of multiplexed tissue images and thus forms a solid basis for a
standardized, open source data analysis.

\bibliographystyle{plain}
\bibliography{20170912_library}

\end{document}
