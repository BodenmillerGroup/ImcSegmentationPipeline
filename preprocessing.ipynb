{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of IMC data for image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script presents the first step of the IMC segmentation pipeline.\n",
    "\n",
    "To get started, please refer to the [Get started guide](docs/index.md).\n",
    "For more information on how to use the `imctools` package, please refer to this [documentation](https://bodenmillergroup.github.io/imctools/).\n",
    "\n",
    "Following this script, you will find an option to download example data.\n",
    "\n",
    "**Requirements for the input data:**\n",
    "\n",
    "We recommend to supply the raw data in form of _one zip archive per acquisition session_.\n",
    "This zip archive should contain the `.mcd` file and all `.txt` files corresponding to one acquisition session.\n",
    "For working with `.txt` files, please look at the older examples.\n",
    "\n",
    "To understand the output format, please refer to the [Output](docs/output.md) documentation.\n",
    "\n",
    "For any feedback please contact: Vito, vito.zanotelli@uzh.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required libraries\n",
    "\n",
    "In the first step, we will load the python libraries that are required for processing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imctools.converters import ome2analysis\n",
    "from imctools.converters import ome2histocat\n",
    "from imctools.converters import mcdfolder2imcfolder\n",
    "from imctools.converters import exportacquisitioncsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Obtain the example data\n",
    "\n",
    "Here, a set of example data is downloaded. \n",
    "These can be used to test the pipeline.\n",
    "When using your own data, please ignore the following code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Specify example input directory\n",
    "fol_example = pathlib.Path('example_data')\n",
    "fol_example.mkdir(exist_ok=True)\n",
    "\n",
    "# Specify urls\n",
    "urls = [('20170905_Fluidigmworkshopfinal_SEAJa.zip',\n",
    "         'https://www.dropbox.com/s/awyq9p7n7dexgyt/20170905_Fluidigmworkshopfinal_SEAJa.zip?dl=1') ,\n",
    "        ('20170906_FluidigmONfinal_SE.zip',\n",
    "         'https://www.dropbox.com/s/0pdt1ke4b07v7zd/20170906_FluidigmONfinal_SE.zip?dl=1')]\n",
    "\n",
    "# Download the data to the example input directory\n",
    "for fn, url in urls:\n",
    "    fn = fol_example / fn\n",
    "    if not fn.exists():\n",
    "        urllib.request.urlretrieve(url, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the inputs\n",
    "\n",
    "Here, you will need to specify where the IMC raw data (in form of `.zip` archives) are stored.\n",
    "The `folders_path_inputs` describes the path where the `.zip` archives are located.\n",
    "Here, we use the example data to run the pre-processing part of the pipeline.\n",
    "The `input_file_regexp` parameter specifies a [regular expression](https://docs.python.org/3/library/re.html) to select all files of interest from the input directory.\n",
    "As an example: if you want to select all files that contain the word \"test\", you would use the regular expression `'.*test.*.zip'`.\n",
    "\n",
    "You will also need to specify the location of the panel file (`file_path_panel`) that contains information regarding the column that contains the metal name (`metal_colname`), the column that contains an identifier if the channel should be used for ilastik training (`ilastik_colname`), and the column that contains an identifier if the channel should be used to generate the final stack of channels (`full_colname`). The latter two arguments specify columns which contain 0s or 1s, 1 meaning the indicated channel is used and 0 meaning the channel is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Path to input folder\n",
    "folders_path_inputs = ['example_data']\n",
    "\n",
    "# Regular expression to select files of interest\n",
    "input_file_regexp = '.*.zip'\n",
    "\n",
    "# Specifications of the panel file\n",
    "file_path_panel = 'config/example_panel.csv'\n",
    "metal_colname = 'Metal Tag'\n",
    "ilastik_colname = 'ilastik'\n",
    "full_colname = 'full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the outputs\n",
    "\n",
    "You will need to specify a single folder where the output files of the pipeline are written out to.\n",
    "Furthermore, we will need to specify a suffix, which will be added to the names of the `.tiff` stacks that are needed for ilastik training and object measurements (see *Generate image stacks for downstream analysis* section below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for OME tiffs\n",
    "folder_path_base = 'analysis'\n",
    "\n",
    "# Suffix to be added to output tiff stacks\n",
    "suffix_full = '_full'\n",
    "suffix_ilastik = '_ilastik'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next chunk, all sub-folders for the output files are generated automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folder_path_base = pathlib.Path(folder_path_base)\n",
    "folders_path_inputs = [pathlib.Path(f) for f in folders_path_inputs]\n",
    "\n",
    "# Output sub-folders\n",
    "folder_path_tiffs = folder_path_base / 'tiffs'\n",
    "folder_path_ilastik= folder_path_base / 'ilastik'\n",
    "folder_path_ome= folder_path_base / 'ometiff'\n",
    "folder_path_cp = folder_path_base / 'cpout'\n",
    "folder_path_cp_input = folder_path_base / 'cpinp'\n",
    "folder_path_histocat = folder_path_base / 'histocat'\n",
    "\n",
    "# Other output\n",
    "file_path_cp_csv = folder_path_cp / 'panel.csv'\n",
    "file_path_full_channels_csv = folder_path_cp_input / 'full_channelmeta.csv'\n",
    "file_path_ilastik_channels_csv = folder_path_cp_input / 'ilastik_channelmeta.csv'\n",
    "file_path_prob_channels_csv = folder_path_cp_input / 'probab_channelmeta_manual.csv'\n",
    "\n",
    "for fol in [folder_path_base, folder_path_analysis, folder_path_ilastik,\n",
    "            folder_path_ome, folder_path_cp, folder_path_histocat,\n",
    "           folder_path_cp_input]:\n",
    "    if not fol.exists():\n",
    "        fol.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `.mcd` files to `.ome.tiff` files\n",
    "\n",
    "In the first step, we will convert the `.zip` archives containing `.mcd` files to folders, which contain `.ome.tiff` files, panoramas and slide overviews using the [mcdfolder_to_imcfolder](https://bodenmillergroup.github.io/imctools/converters/mcdfolder2imcfolder.html#imctools.converters.mcdfolder2imcfolder.mcdfolder_to_imcfolder) function. The `.ome.tiff` files can be read in by commercial and open-source software such as ImageJ using the BioFormats importer. \n",
    "We will store files that can't be processed in the `failed_images` list object to allow quality control.\n",
    "At this stage, only images specified by `input_file_regexp` will be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170906_FluidigmONfinal_SE.zip\n",
      "20170905_Fluidigmworkshopfinal_SEAJa.zip\n"
     ]
    }
   ],
   "source": [
    "failed_images = list()\n",
    "re_fn = re.compile(input_file_regexp)\n",
    "\n",
    "for fol in folders_path_inputs:\n",
    "    for fn in fol.glob('*'):\n",
    "        if re_fn.match(fn.name):\n",
    "            \n",
    "            try:\n",
    "                mcdfolder2imcfolder.mcdfolder_to_imcfolder(input=fn, \n",
    "                                                           output_folder=folder_path_ome,\n",
    "                                                           create_zip=False)\n",
    "                print(fn.name)\n",
    "                \n",
    "            except:\n",
    "                print(fn.name + \" can't be processed!\")\n",
    "                failed_images.append(fn.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also now observe the failed conversions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(failed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export additional metadata\n",
    "\n",
    "In the next section, we will export the metadata associated with the different acquisitions using the [export_acquisition_csv](https://bodenmillergroup.github.io/imctools/converters/exportacquisitioncsv.html#imctools.converters.exportacquisitioncsv.export_acquisition_csv) function as well as a copy of the panel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('analysis/cpout/panel.csv')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export acquisition metadata\n",
    "exportacquisitioncsv.export_acquisition_csv(root_folder=folder_path_ome, \n",
    "                                            output_folder=folder_path_cp_input)\n",
    "\n",
    "# Copy panel to output folder\n",
    "shutil.copy(file_path_panel, file_path_cp_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `.ome.tiff` files to `histoCAT` compatible format\n",
    "\n",
    "In the next step, we will convert the generated `.ome.tiff` files to a format that [histoCAT](https://bodenmillergroup.github.io/histoCAT/) can recognize.\n",
    "For each acquistion (each `.ome.tiff` file), the [omefolder_to_histocatfolder](https://bodenmillergroup.github.io/imctools/converters/ome2histocat.html#imctools.converters.ome2histocat.omefolder_to_histocatfolder) function call produces one folder that contains single channel tiff files. Here, all channels contained in the `.ome.tiff` files are written out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for fol in folder_path_ome.iterdir():\n",
    "    if fol.is_dir():\n",
    "        ome2histocat.omefolder_to_histocatfolder(input_folder=fol, \n",
    "                                                 output_folder=folder_path_histocat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate image stacks for downstream analyses\n",
    "\n",
    "Next, we will generate two stacks of multi-channel `.tiff` images:\n",
    "\n",
    "**1. Full stack:** The full stack contains all channels specified by the \"1\" entries in the `full_colname` column of the panel file. This stack will be later used to measure cell-specific expression features of the selected channels.\n",
    "\n",
    "**2. Ilastik stack:** The ilastik stack contains all channels specified by the \"1\" entries in the `ilastik_colname` column of the panel file. This stack will be used to perform the ilastik training to generate cell, cytoplasm and background probability masks (see [Ilastik training](https://bodenmillergroup.github.io/ImcSegmentationPipeline/ilastik.html)).\n",
    "\n",
    "The [omefolder_to_analysisfolder](https://bodenmillergroup.github.io/imctools/converters/ome2analysis.html#imctools.converters.ome2analysis.omefolder_to_analysisfolder) function takes several arguments:\n",
    "\n",
    "`input_folder` specifies the folder containing the `.ome.tiff` files.  \n",
    "`output_folder` specifies the folder where the `.tiff` stacks should be stored.  \n",
    "`panel_csv_file` specifies the path to the panel file.  \n",
    "`analysis_stacks` takes an array of analysis stack definitions in a tuple format (column, suffix). Here, column specifies the panel column containing 0s and 1s indicating which channels to use and suffix spcifies the suffix to add at the end of the output stacks.\n",
    "`metalcolumn` specifies the panel column that contains the metal tags.\n",
    "\n",
    "We will first generate the stack definition before calling the converter function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define stacks\n",
    "list_analysis_stacks =[\n",
    "    (ilastik_colname, suffix_ilastik),\n",
    "    (full_colname, suffix_full)]\n",
    "\n",
    "# Convert ome.tiffs to tiff stacks\n",
    "ome2analysis.omefolder_to_analysisfolder(input_folder=folder_path_ome, \n",
    "                                         output_folder=folder_path_tiffs, \n",
    "                                         panel_csv_file=file_path_panel,\n",
    "                                         analysis_stacks=(list_analysis_stacks), \n",
    "                                         metalcolumn=metal_colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export additional metadata\n",
    "\n",
    "Finally, we will copy a file that contains the correct order of channels for the exported full stacks and ilastik stacks to the input folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('analysis/cpinp/ilastik_channelmeta.csv')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_full = next(folder_path_analysis.glob(f'*{suffix_full}.csv'))\n",
    "fn_ilastik = next(folder_path_analysis.glob(f'*{suffix_ilastik}.csv'))\n",
    "\n",
    "shutil.copy(fn_full, file_path_full_channels_csv)\n",
    "shutil.copy(fn_ilastik, file_path_ilastik_channels_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also generate channel metadata for the probability stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "probab_meta = [\"CellCenter\", \"CellBorder\", \"Background\"]\n",
    "with open(file_path_prob_channels_csv, 'w') as f:\n",
    "    f.write('\\n'.join(probab_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "This concludes the conversion of the IMC rawdata into usable TIFFs.\n",
    "\n",
    "The pipelines can be found in the `cp4_pipeline` folder in this repository. They were tested in `cellprofiler 4.0.6).\n",
    "\n",
    "The next steps are:\n",
    "\n",
    "### A) Cellprofiler: 1_prepare_ilastik\n",
    "\n",
    "In this module we prepare the data for Ilastik pixel classification, by first removing strong outlier pixels, then scaling the images 2x and then taking random 500x500 crops to do the train the pixel classifier.\n",
    "\n",
    "Note: for large datasets 250x250 crops or smaler should suffice!\n",
    "\n",
    "The following parts of this module need to be adapted:\n",
    "\n",
    "1) File list: choose all files in the `tiff` subfolder\n",
    "\n",
    "2) Default Output Folder: Choose the `ilastik` subfolder\n",
    "\n",
    "No further parts need to be adapted.\n",
    "In our 16 core computer this step takes ca 5 min for the example dataset.\n",
    "\n",
    "\n",
    "### B) Ilatik: Train a pixel classifier\n",
    "\n",
    "This uses the random crops generated in the last step.\n",
    "\n",
    "1) Make a new `pixel classification project`. -> An example project that works with the example data can be found in the 'analysis' subfolder.\n",
    "\n",
    "2) Add the `.h5` random crops: Raw data -> Add Seperate Images -> Select all `.h5` images in the `ilastik` subfolder.\n",
    "\n",
    "3) Proceed to `Feature Selection`\n",
    "\n",
    "4) Select suitable features (or just everything >= 1 pixels)\n",
    "\n",
    "5) Proceed to the classification:\n",
    "\n",
    "    - Add 3 labels:\n",
    "        - 1: Nuclei\n",
    "        - 2: Cytoplasma/membrane\n",
    "        - 3: Background\n",
    "        - -> For large datasets adding the labels can take a while\n",
    "    - Start labeling:\n",
    "        - The box next to `Input Data` can change the channels. What each channel corresponds to can be seen when looking in any of the `..._ilastik.csv` files in the `tiff` folder. The 0 channel correspond to the sum of all channels, very usefull to label the background.\n",
    "        - Use window leveling change the contrast. Right click on the `Input Data` -> `Adjust Thresholds` is also very usefull\n",
    "        - Label opiniated: If you see in the nucleus channel that two nuclei are stuck together but have a faint dip in intensity in between, label this as 2: Cytoplasma. Encyrcle nuclei with Cytoplasma\n",
    "        - Diseable `Live Update` for performance\n",
    "        - Frequently check the `Uncertainties`: This indicates which pixels the classifier profits most if they are labeled. A well trained classifier has low uncertainty within class regions (e.g. Nuclei) and high uncertainty at class borders (e.g. between nuclei and cytoplasma).\n",
    "\n",
    "    - If you think the classifier is well trained, export the probabilities:\n",
    "        - Export Settings -> Source: Probabilities -> Choose Export Image Settings:\n",
    "            - Convert to datatype: Unsigned Integer 16 bit\n",
    "            - Renormalize: check\n",
    "            - Format: Tiff\n",
    "            - File: leave default\n",
    "        - Export all: This generates `_Probabilities.tiff` in the `ilastik` folder. They can be checked using any image viewer\n",
    "            - To generate uncertainty maps (good to identify regions that need training),\n",
    "            run the `Convert probabilities to uncertainties` section `#For training` below. This will put uncertainties in the uncertainty folder.\n",
    "            -> Well trained classifiers have low uncertainty (transparent) everywhere but at class borders which should be white.\n",
    "\n",
    "        - Optional: Train again regions with high uncertainty, then proceed.\n",
    "\n",
    "        - Batch processing: -> Select raw data files -> select all `_s2.h5` files in the `tiff` folder. (sort by filetype, select all `H5` files).\n",
    "            -> This step takes a while and is computationally intensive!\n",
    "            -> Ca 15 min on 10 cores on the example data\n",
    "\n",
    "        - Optional: use the below probability to uncertainty `#For the data` to convert all proabilities to uncertainties, check if there are any regions of high uncertainty and optionally crop the corresponding image part in imagej and add it to the training data.\n",
    "        - Note: store the `ilastik` folder with all the random crops and the trained classifier for reproducibility reasons.\n",
    "        \n",
    "        - A trained\n",
    "\n",
    "### C) Cellprofiler: 2_segment_ilastik\n",
    "\n",
    "This step will segment the probabilities into masks.\n",
    "\n",
    "Things to adapt:\n",
    "\n",
    "1) File list: choose again all files from the `tiffs` folder\n",
    "\n",
    "2) It is important to check the `IdentifyPrimaryObjects` step, if the segmentation settings are suitable!\n",
    "    This might vary strongly between cell/tissue/training and needs attention! Use the test mode and try various settings.\n",
    "    Also note the `smooth` step immediately before: This can be also removed, I just happen get good results with this additional step.\n",
    "\n",
    "3) Also the `MeasureObjectSizeShape` combined with `FilterObjects` is just some personal preference of mine, feel free to change\n",
    "\n",
    "4) `IdentifySecondaryObjects`: Here th mask is expanded to the full cell.\n",
    "\n",
    "5) `Rescale objects`: note that our segmentation was done on 2x upscaled images, this scales the masks down again. Note that potentially also the nuclei mask could be scaled down and further exported and used.\n",
    "\n",
    "6) The `Default Output Path` does not need to be adapted for this module.\n",
    "\n",
    "\n",
    "Note1: Seperating mask generation from mask measurement adds modularity and is thus highly recommended, as generating masks is one of the most resource intensive steps.\n",
    "\n",
    "\n",
    "### D) Cellprofiler: 3_measure_mask\n",
    "\n",
    "This step is not necessary for `HistoCat` only analysis. If `HistoCat` should be used, use the `Generate the histocat folder with masks` section below.\n",
    "\n",
    "#### 3_measure_mask_basic\n",
    "\n",
    "This module measures without considering spillover correction.\n",
    "\n",
    "1) File list: choose again all files from the `tiffs` folder\n",
    "\n",
    "2) View Output settings: set the `Default output folder` to the `cpout` folder and the\n",
    "    `Default input folder` to the `cpint` folder.\n",
    "\n",
    "3) Metadata: update - this will automatically merge the mcd metadata .csv generated earlier in the script with your images.\n",
    "\n",
    "4) Names and types: click update\n",
    "\n",
    "5) `Measure Object Intensity Multichannel`: Adapt the channel numbers. Check the `_full.csv` files in the `tiffs` folder to see how many channels the stack have and adapt accordingly.\n",
    "\n",
    "6) `Measure Image Intensity Multichannel`: Adapt the channel numbers. Check the `_full.csv` files in the `tiffs` folder to see how many channels the stack have and adapt accordingly.\n",
    "\n",
    "Notes:\n",
    "- In this pipeline all the intesities are scaled by `1/(2**16)`\n",
    "- The mapping between channel number c1, c2, c3 corresponds to the position in the `_full.csv`s found in the `tiffs` folder.\n",
    "- The original acquisition description, acquisition frequencies etc can be found in the `Image.csv` output as `Metdata_...` columns.\n",
    "- This outputs a lot of measurements that are acutally of little interest - usually we only look at `meanintensity` per channel and cell.\n",
    "    To reduce the outputs, select in `Export To Spreadsheet` -> `Select Measurements to Export` -> Only the measurements you want (usually all Image measurements and only the `MeanIntensity` fullstack measurements).\n",
    "- The `FullStack` can also be not measured, as it is almost identical to the `FullStackFiltered`.\n",
    "\n",
    "#### 3_measure_mask_compensated\n",
    "This will also have a spillover corrections step - stay tuned!\n",
    "\n",
    "\n",
    "### E) Pipeline output\n",
    "\n",
    "The pipeline output is all in the `cpout` folder.\n",
    "\n",
    "Files and folders:\n",
    "- Image.csv: Image level metadata\n",
    "- var_Image.csv: Metadata for the colums in Image.csv.\n",
    "    This contains also metadata from the IMC such as acquisition coordinates.\n",
    "\n",
    "- {object}.csv: eg cell.csv, contains cell slice level measurements\n",
    "- var_{object}.csv: eg var_cell.csv: contains metadata for the object measurements\n",
    "\n",
    "- panel.csv: a copy of the panel used for the input\n",
    "\n",
    "- Object relationships.csv: Object neighbourhood and other relationships\n",
    "\n",
    "- Experiment.csv: Metadata about the actual measurement run (eg pipeline used,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the histocat folder with masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 1.09 s, total: 2.44 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "suffix_mask = '_mask.tiff'\n",
    "for fol in folder_path_ome.glob('*'):\n",
    "    ome2histocat.omefolder_to_histocatfolder(fol, folder_path_histocat,\n",
    "                                    mask_folder=folder_path_analysis, mask_suffix=suffix_mask, dtype='uint16')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.3.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
